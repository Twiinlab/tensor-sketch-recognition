{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to help intialize random weights for fully connected or convolutional layers, we leave the shape attribute as a parameter for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as init_weights, but for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2D convolution using builtin conv2d from TF. From those docs:\n",
    "\n",
    "Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
    "\n",
    "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "and a filter / kernel tensor of shape\n",
    "`[filter_height, filter_width, in_channels, out_channels]`, this op\n",
    "performs the following:\n",
    "\n",
    "1. Flattens the filter to a 2-D matrix with shape\n",
    "   `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "2. Extracts image patches from the input tensor to form a *virtual*\n",
    "   tensor of shape `[batch, out_height, out_width,\n",
    "   filter_height * filter_width * in_channels]`.\n",
    "3. For each patch, right-multiplies the filter matrix and the image patch\n",
    "   vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a max pooling layer, again using built in TF functions:\n",
    "\n",
    "Performs the max pooling on the input.\n",
    "\n",
    "    Args:\n",
    "      value: A 4-D `Tensor` with shape `[batch, height, width, channels]` and\n",
    "        type `tf.float32`.\n",
    "      ksize: A list of ints that has length >= 4.  The size of the window for\n",
    "        each dimension of the input tensor.\n",
    "      strides: A list of ints that has length >= 4.  The stride of the sliding\n",
    "        window for each dimension of the input tensor.\n",
    "      padding: A string, either `'VALID'` or `'SAME'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the conv2d function, we'll return an actual convolutional layer here that uses an ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a normal fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper (custom functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(pos):\n",
    "    '''\n",
    "    For use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    out = np.zeros(10)\n",
    "    out[pos] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duck lenght 135480\n",
      "smile lenght 124386\n",
      "car lenght 182764\n",
      "pencil lenght 122001\n",
      "star lenght 137619\n",
      "burger lenght 129672\n",
      "cookie lenght 131353\n",
      "rabbit lenght 155288\n",
      "moon lenght 121661\n",
      "icecream lenght 123133\n"
     ]
    }
   ],
   "source": [
    "#duck smile car pencil star burger cookie rabbit moon icecream\n",
    "fileList = ['duck','smile','car','pencil','star','burger','cookie','rabbit','moon','icecream']\n",
    "for i in range(len(fileList)):\n",
    "    print('{} lenght {}'.format(fileList[i], len(np.load('./SKETCH_data/'+fileList[i]+'.npy'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images = []\n",
    "# pos_begin = 0\n",
    "# pos_end = 100\n",
    "# fileList = ['duck','smile','car','pencil','star','burger','cookie','rabbit','moon','icecream']\n",
    "# images = np.array(np.load('./SKETCH_data/'+ fileList[0] +'.npy')[pos_begin:pos_end])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.concatenate((images,np.array(np.load('./SKETCH_data/'+ fileList[1] +'.npy')[pos_begin:pos_end])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(img, predict, label):\n",
    "    plt.title('Predict %s. Label: %d' % (predict, label))\n",
    "    plt.imshow(img.reshape((28,28)), cmap=plt.cm.gray_r)\n",
    "    plt.show()\n",
    "# display(test_x[0], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchImageHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Init SketchImageHelper\")\n",
    "        self.position = 0\n",
    "        \n",
    "        self.batch_x = None\n",
    "        self.batch_y = None\n",
    "        \n",
    "        self.pos_begin = 1000\n",
    "        self.pos_end = 110000\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.fileList = ['duck','smile','car','pencil','star','burger','cookie','rabbit','moon','icecream']\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Batch Images and Labels\")\n",
    "        sampleSize = self.pos_end - self.pos_begin\n",
    "        i = 0\n",
    "        for i in range(len(self.fileList)):\n",
    "            partialImages = np.array(np.load('./SKETCH_data/'+ self.fileList[i] +'.npy')[self.pos_begin:self.pos_end])\n",
    "            self.images.append( partialImages / 255)\n",
    "            self.labels.append(np.full((sampleSize,10), one_hot_encode(i)))\n",
    "\n",
    "        print('batch lenght {}'.format(len(self.images)))\n",
    "        print('batch lenght {}'.format(len(self.labels)))\n",
    "        \n",
    "        \n",
    "    def next_batch(self, batch_size):                          \n",
    "        x = []\n",
    "        y = []\n",
    "        partial_batch = batch_size // len(self.fileList)\n",
    "        i = 0\n",
    "        for i in range(len(self.fileList)):\n",
    "            if i==0:\n",
    "                x = np.array((self.images[i])[self.position:self.position+partial_batch])\n",
    "                y = np.array((self.labels[i])[self.position:self.position+partial_batch])\n",
    "            else:\n",
    "                x = np.concatenate((x,np.array((self.images[i])[self.position:self.position+partial_batch])), axis=0)\n",
    "                y = np.concatenate((y,np.array((self.labels[i])[self.position:self.position+partial_batch])), axis=0)  \n",
    "\n",
    "        \n",
    "        self.position = (self.position + partial_batch)\n",
    "        print(' {}'.format(self.position), end='')\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sih = SketchImageHelper()\n",
    "# sih.set_up_images()\n",
    "# lotx, loty = sih.next_batch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sih.images[0]))\n",
    "# display(sih.images[0][51], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lotx)\n",
    "# display(lotx[4], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lotx, loty = sih.next_batch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lotx)\n",
    "# display(lotx[4], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lotx, loty = sih.next_batch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
    "# You can change the 32 output, that essentially represents the amount of filters used\n",
    "# You need to pass in 32 to the next input though, the 1 comes from the original input of \n",
    "# a single image.\n",
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
    "# You can actually change the 64 output if you want, you can think of that as a representation\n",
    "# of the amount of 6by6 filters used.\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
    "# 64 then just comes from the output of the previous Convolution\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE THE PLACEHOLDER HERE!\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001) # 0.0001\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x lenght 5000\n",
      "test_y lenght 5000\n"
     ]
    }
   ],
   "source": [
    "#duck smile car pencil star burger cookie rabbit moon icecream\n",
    "\n",
    "pos_begin = 0\n",
    "pos_end = 500\n",
    "\n",
    "test_x = np.concatenate((np.array(np.load('./SKETCH_data/duck.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/smile.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/car.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/pencil.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/star.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/burger.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/cookie.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/rabbit.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/moon.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/icecream.npy')[pos_begin:pos_end])), axis=0)\n",
    "test_y = np.concatenate((np.full((pos_end-pos_begin,10), one_hot_encode(0)), np.full((pos_end-pos_begin,10), one_hot_encode(1)), np.full((pos_end-pos_begin,10), one_hot_encode(2)), np.full((pos_end-pos_begin,10), one_hot_encode(3)),\n",
    "                               np.full((pos_end-pos_begin,10), one_hot_encode(4)), np.full((pos_end-pos_begin,10), one_hot_encode(5)), np.full((pos_end-pos_begin,10), one_hot_encode(6)), np.full((pos_end-pos_begin,10), one_hot_encode(7)),\n",
    "                               np.full((pos_end-pos_begin,10), one_hot_encode(8)), np.full((pos_end-pos_begin,10), one_hot_encode(9))), axis=0)\n",
    "\n",
    "print('test_x lenght {}'.format(len(test_x)))\n",
    "print('test_y lenght {}'.format(len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init SketchImageHelper\n",
      "Setting Up Batch Images and Labels\n",
      "batch lenght 10\n",
      "batch lenght 10\n",
      " 50[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.16078431\n",
      "  0.33333333  0.35294118  0.04705882  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.40784314\n",
      "  0.98039216  1.          1.          0.91372549  0.36470588  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.54901961\n",
      "  1.          0.81176471  0.89019608  0.69803922  0.7372549   0.99215686\n",
      "  0.3372549   0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.21568627  1.          0.63529412  1.          1.          1.\n",
      "  0.38431373  0.73333333  0.96862745  0.22745098  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.04705882  0.74509804  0.89019608  0.08235294  0.98823529  1.          1.\n",
      "  0.38039216  0.05882353  0.83529412  0.8627451   0.03137255  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.02352941  0.38431373\n",
      "  0.70196078  0.96862745  1.          0.38039216  0.          0.66666667\n",
      "  1.          0.7254902   0.          0.          0.45882353  1.\n",
      "  0.60784314  0.01176471  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.06666667  0.74901961  1.          0.84313725  0.58431373  0.32156863\n",
      "  0.2         0.19607843  0.04705882  0.18039216  0.01568627  0.          0.\n",
      "  0.01960784  0.59215686  1.          0.32941176  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.75686275  0.96862745  0.6745098   0.85490196  1.          1.\n",
      "  1.          1.          0.4         0.          0.          0.          0.\n",
      "  0.          0.01176471  0.95686275  0.52941176  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.22352941  1.          1.          0.97254902  0.69803922  0.39215686\n",
      "  0.33333333  0.28627451  0.25490196  0.03137255  0.          0.          0.\n",
      "  0.          0.          0.          0.89019608  0.61960784  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.61960784  0.9372549   0.36862745  0.05882353  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.15294118  1.          0.4627451   0.23529412\n",
      "  0.07058824  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.54901961  0.95686275  0.08235294  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.02352941  0.34509804  0.87843137  1.          1.          1.\n",
      "  0.98431373  0.65490196  0.02745098  0.          0.          0.          0.\n",
      "  0.          0.          0.20784314  0.98431373  0.95686275  0.71372549\n",
      "  0.56862745  0.42352941  0.28235294  0.23921569  0.52941176  0.01176471\n",
      "  0.          0.          0.          0.50980392  1.          1.\n",
      "  0.80392157  0.34509804  0.2627451   0.51372549  0.98823529  0.51372549\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.1372549   0.56470588  0.78039216  0.92156863  1.          1.          1.\n",
      "  1.          0.96078431  0.89411765  0.82745098  0.86666667  1.          1.\n",
      "  0.54509804  0.00392157  0.          0.          0.1372549   0.97254902\n",
      "  0.53333333  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.0627451\n",
      "  0.32156863  0.99215686  0.72941176  0.51372549  0.58039216  0.64705882\n",
      "  0.62352941  0.43529412  0.21176471  0.          0.          0.06666667\n",
      "  0.39607843  0.89803922  0.93333333  0.08235294  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.49411765  0.98431373  0.07843137  0.          0.\n",
      "  0.          0.          0.          0.01568627  0.37647059  0.70980392\n",
      "  0.97647059  1.          0.76862745  0.17647059  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.82352941  0.72941176  0.          0.\n",
      "  0.          0.          0.          0.          0.27843137  1.          1.\n",
      "  1.          0.88235294  0.25490196  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.12156863  1.          0.41176471  0.          0.\n",
      "  0.          0.          0.          0.          0.00392157  0.17254902\n",
      "  0.26666667  0.39607843  0.85490196  0.99215686  0.11764706  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.22745098  1.          0.25098039\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.39215686  1.          0.14901961\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.2627451   1.\n",
      "  0.21960784  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.22352941  0.52941176  0.96862745  0.78823529\n",
      "  0.00392157  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.28235294  1.          0.25098039  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.17647059  1.          1.\n",
      "  0.97647059  0.10980392  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.05882353  0.89803922  0.78431373  0.01176471  0.          0.\n",
      "  0.          0.          0.07843137  0.31764706  0.04313725  0.19215686\n",
      "  0.4745098   1.          0.40784314  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.31372549  1.          0.6627451\n",
      "  0.05490196  0.          0.          0.          0.36078431  1.\n",
      "  0.98039216  0.98431373  1.          1.          1.          0.87058824\n",
      "  0.14117647  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.41960784  0.97647059  0.85490196  0.19215686  0.          0.          0.\n",
      "  0.78039216  0.96078431  0.9372549   0.87058824  0.50588235  0.38823529\n",
      "  0.96862745  0.57647059  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.20392157  0.87058824  0.96862745  0.17647059\n",
      "  0.          0.          0.04705882  0.23137255  0.08235294  0.08627451\n",
      "  0.31764706  0.74901961  1.          0.4745098   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.0627451\n",
      "  0.47843137  0.07058824  0.          0.          0.37647059  1.          1.\n",
      "  1.          1.          0.8627451   0.41176471  0.00392157  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.01568627  0.23921569\n",
      "  0.40392157  0.40784314  0.22745098  0.00784314  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# sih = SketchImageHelper()\n",
    "# sih.set_up_images()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(init)\n",
    "#     batch_x , batch_y = sih.next_batch(500)\n",
    "    \n",
    "#     print(batch_x[0])\n",
    "#     print(batch_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init SketchImageHelper\n",
      "Setting Up Batch Images and Labels\n",
      "batch lenght 10\n",
      "batch lenght 10\n"
     ]
    }
   ],
   "source": [
    "sih = SketchImageHelper()\n",
    "sih.set_up_images()\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT\n",
      " 50\n",
      "\n",
      "step 0\n",
      "Accuracy is:\n",
      "0.1156\n",
      " 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700 1750 1800 1850 1900 1950 2000 2050 2100 2150 2200 2250 2300 2350 2400 2450 2500 2550\n",
      "\n",
      "step 50\n",
      "Accuracy is:\n",
      "0.6166\n",
      " 2600 2650 2700 2750 2800 2850 2900 2950 3000 3050 3100 3150 3200 3250 3300 3350 3400 3450 3500 3550 3600 3650 3700 3750 3800 3850 3900 3950 4000 4050 4100 4150 4200 4250 4300 4350 4400 4450 4500 4550 4600 4650 4700 4750 4800 4850 4900 4950 5000\n",
      "\n",
      "FINAL Accuracy is:\n",
      "0.6946\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 100\n",
    "\n",
    "print('INIT')\n",
    "sess.run(init)\n",
    "\n",
    "for j in range(steps):\n",
    "    # print('.', end='')\n",
    "    batch_x , batch_y = sih.next_batch(500)\n",
    "    sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "\n",
    "    # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "    if j%50 == 0:\n",
    "        print('\\n')\n",
    "        print('step {}'.format(j))\n",
    "        print('Accuracy is:')\n",
    "        # Test the Train Model\n",
    "        matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "        acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "        print(sess.run(acc,feed_dict={x:test_x,y_true:test_y,hold_prob:1.0}))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('FINAL Accuracy is:')\n",
    "print(sess.run(acc,feed_dict={x:test_x,y_true:test_y,hold_prob:1.0}))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_11:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "evalImage = (np.load('./SKETCH_data/duck.npy')[501] / 255)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (784,) for Tensor 'Placeholder_6:0', which has shape '(?, 784)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-b7c4bf83f107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mevalImage\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclassification\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1101\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (784,) for Tensor 'Placeholder_6:0', which has shape '(?, 784)'"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "# y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "evalImage = (np.load('./SKETCH_data/duck.npy')[501] / 255)\n",
    "\n",
    "feed_dict = {x: evalImage , y_true: np.zeros((1, 10)) }\n",
    "\n",
    "classification = sess.run(y_pred, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(evalImage, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b784655c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Job!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
