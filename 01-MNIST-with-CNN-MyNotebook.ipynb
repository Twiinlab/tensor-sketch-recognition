{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SKETCH_data/train-images-idx3-ubyte.gz\n",
      "Extracting SKETCH_data/train-labels-idx1-ubyte.gz\n",
      "Extracting SKETCH_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting SKETCH_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"SKETCH_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to help intialize random weights for fully connected or convolutional layers, we leave the shape attribute as a parameter for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as init_weights, but for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2D convolution using builtin conv2d from TF. From those docs:\n",
    "\n",
    "Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
    "\n",
    "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "and a filter / kernel tensor of shape\n",
    "`[filter_height, filter_width, in_channels, out_channels]`, this op\n",
    "performs the following:\n",
    "\n",
    "1. Flattens the filter to a 2-D matrix with shape\n",
    "   `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "2. Extracts image patches from the input tensor to form a *virtual*\n",
    "   tensor of shape `[batch, out_height, out_width,\n",
    "   filter_height * filter_width * in_channels]`.\n",
    "3. For each patch, right-multiplies the filter matrix and the image patch\n",
    "   vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a max pooling layer, again using built in TF functions:\n",
    "\n",
    "Performs the max pooling on the input.\n",
    "\n",
    "    Args:\n",
    "      value: A 4-D `Tensor` with shape `[batch, height, width, channels]` and\n",
    "        type `tf.float32`.\n",
    "      ksize: A list of ints that has length >= 4.  The size of the window for\n",
    "        each dimension of the input tensor.\n",
    "      strides: A list of ints that has length >= 4.  The stride of the sliding\n",
    "        window for each dimension of the input tensor.\n",
    "      padding: A string, either `'VALID'` or `'SAME'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the conv2d function, we'll return an actual convolutional layer here that uses an ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a normal fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper (custom functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(pos):\n",
    "    '''\n",
    "    For use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    out = np.zeros(10)\n",
    "    out[pos] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duck lenght 135480\n",
      "smile lenght 124386\n",
      "car lenght 182764\n",
      "pencil lenght 122001\n",
      "star lenght 137619\n",
      "burger lenght 129672\n",
      "cookie lenght 131353\n",
      "rabbit lenght 155288\n",
      "moon lenght 121661\n",
      "icecream lenght 123133\n"
     ]
    }
   ],
   "source": [
    "#duck smile car pencil star burger cookie rabbit moon icecream\n",
    "fileList = ['duck','smile','car','pencil','star','burger','cookie','rabbit','moon','icecream']\n",
    "for i in range(len(fileList)):\n",
    "    print('{} lenght {}'.format(fileList[i], len(np.load('./SKETCH_data/'+fileList[i]+'.npy'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# images = []\n",
    "# pos_begin = 0\n",
    "# pos_end = 100\n",
    "# fileList = ['duck','smile','car','pencil','star','burger','cookie','rabbit','moon','icecream']\n",
    "# images = np.array(np.load('./SKETCH_data/'+ fileList[0] +'.npy')[pos_begin:pos_end])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.concatenate((images,np.array(np.load('./SKETCH_data/'+ fileList[1] +'.npy')[pos_begin:pos_end])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SketchImageHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Init SketchImageHelper\")\n",
    "        self.position = 0\n",
    "        \n",
    "        self.batch_x = None\n",
    "        self.batch_y = None\n",
    "        \n",
    "        self.pos_begin = 10000\n",
    "        self.pos_end = 110000\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.fileList = ['duck','smile','car','pencil','star','burger','cookie','rabbit','moon','icecream']\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Batch Images and Labels\")\n",
    "        # sampleSize = self.pos_end - self.pos_begin\n",
    "        # self.batch_x = np.concatenate((np.array(np.load('./SKETCH_data/duck.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/smile.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/car.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/pencil.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/star.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/burger.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/cookie.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/rabbit.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/moon.npy')[self.pos_begin:self.pos_end]),np.array(np.load('./SKETCH_data/icecream.npy')[self.pos_begin:self.pos_end])), axis=0)\n",
    "        # self.batch_y = np.concatenate((np.full((sampleSize,10), one_hot_encode(0)), np.full((sampleSize,10), one_hot_encode(1)), np.full((sampleSize,10), one_hot_encode(2)), np.full((sampleSize,10), one_hot_encode(3)),\n",
    "        #                                np.full((sampleSize,10), one_hot_encode(4)), np.full((sampleSize,10), one_hot_encode(5)), np.full((sampleSize,10), one_hot_encode(6)), np.full((sampleSize,10), one_hot_encode(7)),\n",
    "        #                                np.full((sampleSize,10), one_hot_encode(8)), np.full((sampleSize,10), one_hot_encode(9))), axis=0)\n",
    "        sampleSize = self.pos_end - self.pos_begin\n",
    "        i = 0\n",
    "        for i in range(len(self.fileList)):\n",
    "            if i==0:\n",
    "                self.images = np.array(np.load('./SKETCH_data/'+ self.fileList[i] +'.npy')[self.pos_begin:self.pos_end])\n",
    "                self.labels = np.full((sampleSize,10), one_hot_encode(i))\n",
    "            else:\n",
    "                self.images = np.concatenate((self.images,np.array(np.load('./SKETCH_data/'+ self.fileList[i] +'.npy')[self.pos_begin:self.pos_end])), axis=0)\n",
    "                self.labels = np.concatenate((self.labels,np.full((sampleSize,10), one_hot_encode(i))), axis=0)\n",
    "\n",
    "            # self.batch.append({'x': xdata ,'y': ydata})\n",
    "            # self.batch[i] = np.array( (x,y), dtype=[('x',float),('y', np.int32, (10,))])\n",
    "    \n",
    "        print('batch lenght {}'.format(len(self.images)))\n",
    "        print('batch lenght {}'.format(len(self.labels)))\n",
    "        \n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        # x = self.batch_x[self.i:self.i+batch_size]\n",
    "        # y = self.batch_y[self.i:self.i+batch_size]\n",
    "        # self.i = (self.i + batch_size)\n",
    "        # print(' {}'.format(self.i), end='')                             \n",
    "        x = []\n",
    "        y = []\n",
    "        partial_batch = batch_size // len(self.fileList)\n",
    "        i = 0\n",
    "        for i in range(len(self.fileList)):\n",
    "            if i==0:\n",
    "                x = np.array(self.images[self.position:partial_batch])\n",
    "                y = np.array(self.labels[self.position:partial_batch])\n",
    "            else:\n",
    "                x = np.concatenate((x,np.array(self.images)[self.position:partial_batch]), axis=0)\n",
    "                y = np.concatenate((y,np.array(self.labels)[self.position:partial_batch]), axis=0)  \n",
    "\n",
    "        \n",
    "        self.position = (self.position + partial_batch)\n",
    "        print(' {}'.format(self.position), end='')\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sih = SketchImageHelper()\n",
    "# sih.set_up_images()\n",
    "# lot = sih.next_batch(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
    "# You can change the 32 output, that essentially represents the amount of filters used\n",
    "# You need to pass in 32 to the next input though, the 1 comes from the original input of \n",
    "# a single image.\n",
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
    "# You can actually change the 64 output if you want, you can think of that as a representation\n",
    "# of the amount of 6by6 filters used.\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
    "# 64 then just comes from the output of the previous Convolution\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE THE PLACEHOLDER HERE!\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x lenght 5000\n",
      "test_y lenght 5000\n"
     ]
    }
   ],
   "source": [
    "#duck smile car pencil star burger cookie rabbit moon icecream\n",
    "\n",
    "pos_begin = 0\n",
    "pos_end = 500\n",
    "\n",
    "test_x = np.concatenate((np.array(np.load('./SKETCH_data/duck.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/smile.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/car.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/pencil.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/star.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/burger.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/cookie.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/rabbit.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/moon.npy')[pos_begin:pos_end]),np.array(np.load('./SKETCH_data/icecream.npy')[pos_begin:pos_end])), axis=0)\n",
    "test_y = np.concatenate((np.full((pos_end-pos_begin,10), one_hot_encode(0)), np.full((pos_end-pos_begin,10), one_hot_encode(1)), np.full((pos_end-pos_begin,10), one_hot_encode(2)), np.full((pos_end-pos_begin,10), one_hot_encode(3)),\n",
    "                               np.full((pos_end-pos_begin,10), one_hot_encode(4)), np.full((pos_end-pos_begin,10), one_hot_encode(5)), np.full((pos_end-pos_begin,10), one_hot_encode(6)), np.full((pos_end-pos_begin,10), one_hot_encode(7)),\n",
    "                               np.full((pos_end-pos_begin,10), one_hot_encode(8)), np.full((pos_end-pos_begin,10), one_hot_encode(9))), axis=0)\n",
    "\n",
    "print('test_x lenght {}'.format(len(test_x)))\n",
    "print('test_y lenght {}'.format(len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init SketchImageHelper\n",
      "Setting Up Batch Images and Labels\n",
      "batch lenght 1000000\n",
      "batch lenght 1000000\n",
      "INIT\n",
      " 50\n",
      "\n",
      "step 0\n",
      "Accuracy is:\n",
      "0.1034\n",
      " 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700"
     ]
    }
   ],
   "source": [
    "steps = 150\n",
    "\n",
    "# self.pos_begin = 5000\n",
    "# self.pos_end = 15000\n",
    "sih = SketchImageHelper()\n",
    "sih.set_up_images()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    print('INIT')\n",
    "    sess.run(init)\n",
    "    \n",
    "    for j in range(steps):\n",
    "        # print('.', end='')\n",
    "        batch = sih.next_batch(500)\n",
    "        sess.run(train,feed_dict={x:batch[0],y_true:batch[1],hold_prob:0.5})\n",
    "\n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if j%50 == 0:\n",
    "            print('\\n')\n",
    "            print('step {}'.format(j))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:test_x,y_true:test_y,hold_prob:1.0}))\n",
    "            \n",
    "    \n",
    "    print('\\n')\n",
    "    print('FINAL Accuracy is:')\n",
    "    print(sess.run(acc,feed_dict={x:test_x,y_true:test_y,hold_prob:1.0}))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Job!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
